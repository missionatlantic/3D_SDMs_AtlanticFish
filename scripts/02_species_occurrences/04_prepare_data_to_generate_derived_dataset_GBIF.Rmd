---
title: "04_prepare_data_to_generate_derived_dataset_file"
author: "Mireia Valle"
date: "2024-01-12"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warming = FALSE)
```

# Description

Script to remove outliers from the species occurrence data based on distance.

# Load libraries ---------------------------------------------------
```{r}
library(here) #enable easy file referencing 
library(ggplot2) #plotting
library(tidyverse)
library(R.utils)#loadToEnv
library(glue)#glue
```

#Loading species id
```{r}
species <- read.csv (here::here ("data","derived_data", "02_species_occurrences","species_list_FINAL_hemispheres_automatic.csv"),  sep = ",")

species <- species %>% 
  dplyr:: select (-X) 

n <- data.frame(species$SP)

names(n)

n <- n %>%
  dplyr::rename (id = "species.SP")

n <- str_remove(n$id, "SP")

n <- as.numeric (n)

```

#Load species datasets
```{r}

for (i in n){

#Load species presence data without outliers
  
SP <- loadToEnv(file.path("data", "derived_data" , "02_species_occurrences", "02_species_occurrences_no_outliers_automatic", paste0("SP",i, ".RData")))[[paste0("SP",i)]]
  

derived_dataset <- SP %>% 
    group_by(datasetKey, source) %>% 
    summarize (n = n())
    
write.csv(derived_dataset, file=here::here ("data", "derived_data" , "02_species_occurrences", "04_derived_datasets" , paste0("derived_dataset_gbif_obis_SP", i, "_", SP$scientificName[i],".csv")), row.names=F)
  
}

```

# Generate an overall derived dataset for all downloaded occurrences
```{r}

files <- list.files(here::here ("data", "derived_data" , "02_species_occurrences", "04_derived_datasets"), pattern = "*.csv", full.names = TRUE)

data <- lapply(files, read.csv, header = TRUE, stringsAsFactors = FALSE, row.names = NULL)

df <- do.call(rbind.data.frame, data)

df2 <- df %>% 
  group_by(datasetKey, source) %>% 
  summarize (n = sum(n)) %>% 
  drop_na()

write.csv(df2, file=here::here ("data", "derived_data" , "02_species_occurrences", "04_derived_datasets" , "derived_dataset_obis_gbif.csv"), row.names=F)

df3 <- df %>% 
  dplyr::filter(source == "gbif.org") %>% 
  group_by(datasetKey) %>% 
  summarize (n = sum(n)) %>% 
  drop_na()

write.csv(df3, file=here::here ("data", "derived_data" , "02_species_occurrences", "04_derived_datasets" , "derived_dataset_gbif.csv"), row.names=F)

```

With this derived dataset information file created you have to make sure to deposit your dataset somewhere publicly accessible (e.g. Zenodo). When youâ€™re ready, go to the derived dataset tool from GBIF: https://www.gbif.org/derived-dataset/register (you might need to register if you are not registered yet) fill in the form, upload the last .csv we have created (derived_dataset_gbif.csv) and submit the form. You will get a doi for your derived dataset.



