---
title: "cumulative_prob_2_probability"
author: "M Valle"
date: "31/5/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warming = FALSE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file()) # to set up the root directory to the R project path. otherwise knitr uses the path of the markdown document as root directory
```

#Script information

With this script we load the bricks that contain 47 layers but from the quantile depth the values are NA and that are masked to Atlantic division of the species, and we calculate HS Total value summing up all probabilities from all depths, we scaled the probabilities in accordance to the total HS value, we save scaled cumulative probability brick maps for each species. Finally we summed up the probabilities of all layers and save a raster with the resulting sum of scaled probabilities and save it. 

Loading libraries
```{r}
library(sf)
library(rgdal)
library(stringr)
library(tidyverse)
library(ggpubr)
library(hrbrthemes) # theme_ipsum
library(raster) #read brick
library(prevR)#point.in.SpatialPolygons
library(gtools)#mixedsort
library(readxl)
```

#Loading selected species for modelling 

```{r}
species <- read.csv (here::here ("data", "derived_data","outputs_for_modelling", "species_for_modelling.csv"),  sep = ",")

species <- species %>% 
  dplyr:: select ( -X) 

names <- read_excel (here::here ("data", "derived_data", "01_species_catches", "fish_and_tuna_long_list_75_Atlantic.xlsx"))

filenames_sp <- names$TaxonName


head(names)

n <- data.frame(species$SP)

names(n)

n <- n %>% 
  dplyr::rename (id = "species.SP")

n <- str_remove(n$id, "SP")

n <- as.numeric (n)

```

Loop to  

1) Calculate HS total value considering only cells within the Atlantic division corresponding to the species and only depth layers determined by depth quantile 0.99
2) Calculate scaled probabilities based on hs total 
3) save scaled probabilities by depth to a raster brick  
4) sum up scaled probabilities by depth and save them as raster 

Create a df
```{r}
sum_cumulative_prob_redistributed <-matrix(NA,ncol = 4, nrow = 76)
```

```{r}
for(i in n){
  
  print(i)
  
  #load HSM brick 
  HSM_brick <- brick (here::here ("data", "derived_data", "models_sp00001", "rasters_set_by_species", "HSM_masked_quantile_atl_division", paste0("HSM_masked_quantile_atl_division_SP",i,".tif")))
  
  dim(HSM_brick)
  
  #### Transforming from stack to table
  HSM_brick_df <- as.data.frame(HSM_brick, xy=TRUE)
  
  summary(HSM_brick_df)
  
#------------------------------------------------------#  
#1) Calculate HS total value
#-----------------------------------------------# 
 
  ##remove XY coordinates 
  HSM_brick_df_subset <-  HSM_brick_df %>% 
    dplyr::select (-x, -y)
 
  #first create a new column with the sum of all rows (considering only the selected depth levels)
  HS_total <- HSM_brick_df_subset %>% 
    dplyr::mutate (hsm_sum = rowSums(., na.rm =TRUE))
  
  #calculate the total of the created column  
  HS_total <- sum(HS_total$hsm_sum, na.rm =TRUE)
  
  #HS_total

#---------------------------------------------------------#
#2) Calculate scaled probabilities based on hs total (summed up only considering those cells within the corresponding atlantic division of the species and the 0.99 depth layers)
#-----------------------------------------------------------# 
  
  #we select the whole data frame which contains all depth levels and rename columns adding hs_
    # assign new names to depth level probabilities
  names (HSM_brick_df) <- c("x",
                          "y", 
                           "hs_0", 
                           "hs_5", 
                           "hs_10",
                           "hs_15", 
                           "hs_20", 
                           "hs_25",
                           "hs_30", 
                           "hs_35", 
                           "hs_40", 
                           "hs_45", 
                           "hs_50", 
                           "hs_55",
                           "hs_60", 
                           "hs_65",  
                           "hs_70",
                           "hs_75", 
                           "hs_80", 
                           "hs_85", 
                           "hs_90", 
                           "hs_95", 
                           "hs_100",  
                           "hs_125", 
                           "hs_150", 
                           "hs_175", 
                           "hs_200", 
                           "hs_225",  
                           "hs_250", 
                           "hs_275",  
                           "hs_300", 
                           "hs_325", 
                           "hs_350",
                           "hs_375", 
                           "hs_400", 
                           "hs_425", 
                           "hs_450", 
                           "hs_475", 
                           "hs_500", 
                           "hs_550", 
                           "hs_600", 
                           "hs_650", 
                           "hs_700", 
                           "hs_750", 
                           "hs_800",
                           "hs_850", 
                           "hs_900", 
                           "hs_950",
                           "hs_1000")
  
  #summary(HSM_brick_df)
  
  #create a new data frame with new columns of cumulative probability 
                  
    HSM_2_cumulative_prob <- HSM_brick_df %>% 
      dplyr::mutate (prob_depth_0 = (hs_0*1)/HS_total) %>% 
      dplyr::mutate (prob_depth_5 = (hs_5*1)/HS_total) %>% 
      dplyr::mutate (prob_depth_10= (hs_10*1)/HS_total)%>% 
      dplyr::mutate (prob_depth_15= (hs_15*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_20= (hs_20*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_25= (hs_25*1)/HS_total)%>% 
      dplyr::mutate (prob_depth_30= (hs_30*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_35= (hs_35*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_40= (hs_40*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_45= (hs_45*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_50= (hs_50*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_55= (hs_55*1)/HS_total)%>% 
      dplyr::mutate (prob_depth_60= (hs_60*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_65= (hs_65*1)/HS_total)%>%   
      dplyr::mutate (prob_depth_70= (hs_70*1)/HS_total)%>% 
      dplyr::mutate (prob_depth_75= (hs_75*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_80= (hs_80*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_85= (hs_85*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_90= (hs_90*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_95= (hs_95*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_100= (hs_100*1)/HS_total)%>%   
      dplyr::mutate (prob_depth_125= (hs_125*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_150= (hs_150*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_175= (hs_175*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_200= (hs_200*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_225= (hs_225*1)/HS_total)%>%   
      dplyr::mutate (prob_depth_250= (hs_250*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_275= (hs_275*1)/HS_total)%>%   
      dplyr::mutate (prob_depth_300= (hs_300*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_325= (hs_325*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_350= (hs_350*1)/HS_total)%>% 
      dplyr::mutate (prob_depth_375= (hs_375*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_400= (hs_400*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_425= (hs_425*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_450= (hs_450*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_475= (hs_475*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_500= (hs_500*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_550= (hs_550*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_600= (hs_600*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_650= (hs_650*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_700= (hs_700*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_750= (hs_750*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_800= (hs_800*1)/HS_total)%>% 
      dplyr::mutate (prob_depth_850= (hs_850*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_900= (hs_900*1)/HS_total)%>%  
      dplyr::mutate (prob_depth_950= (hs_950*1)/HS_total)%>% 
      dplyr::mutate (prob_depth_1000 =(hs_1000*1)/HS_total)
  
summary (HSM_2_cumulative_prob)
names (HSM_2_cumulative_prob)

HSM_2_cumulative_prob <- HSM_2_cumulative_prob %>% 
  dplyr::select (-c(3:49))

names (HSM_2_cumulative_prob)

#-------------------------------------------------------------#
#3) save scaled probability maps by depth to a raster brick    
#------------------------------------------------------#    

#transform to raster
    HSM_2_cumulative_prob.r <- rasterFromXYZ(HSM_2_cumulative_prob)
    
    plot(HSM_2_cumulative_prob.r)
    
    #save brick
    writeRaster(HSM_2_cumulative_prob.r,
            filename=here::here ("data", "derived_data", "models_sp00001", "rasters_set_by_species","cumulative_prob_bricks", paste0("HSM_2_cumulative_prob_brick_SP",i)),
            format="GTiff",
            overwrite=TRUE,
            options=c("INTERLEAVE=BAND","COMPRESS=LZW"))
    
    
#--------------------------------------------------------------#
#4) sum up scaled probabilities and save them as raster  
#-------------------------------------------------------#
       
    #sum of catches for plotting
    HSM_2_cumulative_prob <- HSM_2_cumulative_prob %>%
      dplyr::mutate (cumulative_prob_sum = rowSums(.[,3:49], na.rm =TRUE)) %>%      
      dplyr::select(x, y, cumulative_prob_sum)
    
    summary(HSM_2_cumulative_prob)
    
  ggplot() +
     geom_point(data = HSM_2_cumulative_prob, aes(x=x, y=y, colour = cumulative_prob_sum), size = 1)
    
    #transform to raster
    HSM_2_cumulative_prob.r <- rasterFromXYZ(HSM_2_cumulative_prob)

    #plot(HSM_2_cumulative_prob.r)

    #save raster
    writeRaster(HSM_2_cumulative_prob.r,
            filename=here::here ("data", "derived_data", "models_sp00001", "rasters_set_by_species", "sum_cumulative_probabilty_HSM", paste0("cumulative_prob_sum_SP",i)),
            format="GTiff",
            overwrite=TRUE,
            options=c("INTERLEAVE=BAND","COMPRESS=LZW"))
    
    
    #check if the sum of the probabilities is equal to the 1. To do this we need to filter the cells according to the division of the atlantic to which the species corresponds to:

    #calculate the sum of the catches
    redistributed <- sum(HSM_2_cumulative_prob$cumulative_prob_sum)


    #fill in the df
    sum_cumulative_prob_redistributed[i,]<- c(paste0("SP",i),
                                      paste0(filenames_sp[i]),
                                      redistributed, 
                                      HS_total)
    
}# end of loop

sum_cumulative_prob_redistributed <- as.data.frame(sum_cumulative_prob_redistributed)

names(sum_cumulative_prob_redistributed) <- c("SP", "SN", "sum_redistributed", "HS_total")

sum_cumulative_prob_redistributed <- sum_cumulative_prob_redistributed %>% 
  drop_na(SP)

write.csv(sum_cumulative_prob_redistributed, file=here::here ("data", "derived_data", "models_sp00001","rasters_set_by_species", "sum_cumulative_probabilty_HSM",  "sum_cumulative_prob_redistributed.csv"))
```


